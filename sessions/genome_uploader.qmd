---
title: "The genome_uploader: tutorial"
date: 2024-09-10
license: "Apache 2.0"
order: 4
author:
  - name: Germana Baldi
    orcid: 0000-0003-1719-5206
    email: germanab@ebi.ac.uk
    affiliation: 
      - name: EMBL-EBI
        url: www.ebi.ac.uk
---

This session will simulate genomes registration and submission with the `genome_uploader`, a tool developed within MGnify to facilitate the upload of bins and MAGs to the ENA (European Nucleotide Archive).

Letâ€™s first move to the `genomeuploader` root directory. Open a terminal and type:

```bash
cd /home/training/genomeuploader/
```

## The genome_uploader and its metadata handling

As Maira thoroughly explained in the theory session, bin and MAG submission undergoes 3 different steps:

* Register binned and/or MAG samples
* Generate manifest files
* Submit assemblies with Webin-CLI

The `genome_uploader` takes care of these 3 steps. The first two are executed together, while the third one needs an extra command to submit previously generated files to ENA servers.

:::{.callout-step .callout-tip}
Your task is to generate a tsv table with sample metadata describing the genomes you want to register and submit.
:::

Similarly to yesterday's practical, you will be free to insert values as you wish, as long as regular expressions and mandatory fields described in the checklist are respected. You will need to select whether you are uploading bins or MAGs, and select your checklist accordingly. 

:::{.callout-note}
To register a sample, a relative set of metadata must be filled according to the selected checklist. Some of them are mandatory, while some others are only recommended. The `genome_uploader` will automatically pick the right checklist depending on the input flag:

* __GSC MIMAG__ for MAG samples (`-mag`)
* __ENA binned metagenome__ for binned samples (`-bin`)
:::

The main difference between bins and MAGs lies in the uniqueness and the quality of your data. Within an ENA study, there should only be one MAG per species, which should be the highest quality representative genome per predicted species. 

The generated table will be similar to the following:

::: {.table-responsive}
| genome_name | genome_path | accessions | assembly_software | binning_software | binning_parameters | stats_generation_software | completeness | contamination | genome_coverage | metagenome | co-assembly | broad_environment | local_environment | environmental_medium | rRNA_presence | taxonomy_lineage |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| L_sakei | path/to/L_sakei.fa.gz | SRR11910206 | megahit_v1.2.9 | metabat_v1.2 | default | CheckM2_v1.0.1 | 99.7 | 0.38 | 27 | marine sediment metagenome | False | marine | coast | coastal sediment | True | d__Bacteria;p__Firmicutes;c__Bacilli;o__Lactobacillales;f__Lactobacillaceae;g__Latilactobacillus;s__Lactobacillus sakei |
:::

With columns indicating:

  * `genome_name`: genome id (unique string identifier)
  * `accessions`: run(s) or assembly(ies) the genome was generated from (DRR/ERR/SRRxxxxxx for runs, DRZ/ERZ/SRZxxxxxx for assemblies). If the genome was generated by a co-assembly of multiple runs, separate them with a comma.
  * `assembly_software`: name of the assembly software used, with version (e.g. metaSPAdes_4.0.0)
  * `binning_software`: name of the binning software used, with version (e.g. metabat_v1.2)
  * `binning_parameters`: binning parameters
  * `stats_generation_software`: name of the statistics generation software used, with version (e.g.checkM_v1)
  * `completeness`: `float`
  * `contamination`: `float`
  * `rRNA_presence`: `True/False` if all among 5S, 16S, and 23S genes, and at least 18 tRNA genes, have been detected in the genome
  * `NCBI_lineage`: full NCBI lineage, either in tax ids (`integers`) or `strings`. Format: x;y;z;...
  * `metagenome`: needs to be listed in the taxonomy tree [here](<https://www.ebi.ac.uk/ena/browser/view/408169?show=tax-tree>) (you might need to press "Tax tree - Show" in the right most section of the page)
  * `co-assembly`: `True/False`, whether the genome was generated from a co-assembly.
  * `genome_coverage` : genome coverage against raw reads
  * `genome_path`: path to genome to upload (already compressed)
  * `broad_environment`: `string` (explanation following)
  * `local_environment`: `string` (explanation following)
  * `environmental_medium`: `string` (explanation following)

According to ENA checklist's guidelines, 'broad_environment' describes the broad ecological context of a sample - desert, taiga, coral reef, ... 'local_environment' is more local - lake, harbour, cliff, ... 'environmental_medium' is either the material displaced by the sample, or the one in which the sample was embedded prior to the sampling event - air, soil, water, ... For host-associated metagenomic samples, the three variables can be defined similarly to the following example for the chicken gut metagenome: "chicken digestive system", "digestive tube", "caecum". 

If your genome was generated from raw reads available on the INSDC (including ENA and GenBank), the `genome_uploader` will automatically inherit relevant metadata for that sample to make. For example, if you are submitting a MAG generated from read SRR11910206, some of the sample metadata will be inherited for the genome sample registration (e.g. `collection_date`, `isolation_source`). 

Take a look at the [GCS MIMAG checklist](https://www.ebi.ac.uk/ena/browser/view/ERC000047) as a reference. You will notice that bins and MAGs checklists are very similar, as mandatory fields are the same. You can compare it with the [bins checklist](https://www.ebi.ac.uk/ena/browser/view/ERC000050) yourself.

## Considerations

Here we suggest a hypothetical scenario you might want to follow to make the metadata search more interesting

Suppose your original dataset was small, very small, and it only generated three bins. You'd be surprised but yes, it happens sometimes. Two of these bins represent the same species, but their statistics are extremely different. One assembled quite well, while the other one was highly contaminated. One would be considered "medium quality", while the other "high quality". 

:::{.callout-tip}
The INSDC defines a genome as high-quality when: 

![](genome_uploader/high-quality-def-genomeUploader.png)
::: 

According to what we previously mentioned, two of these bins could be categorised as MAGs, while the lower-quality bin would stay as a bin.

:::{.callout-tip}
Taxonomies can be listed in either NCBI or GTDB format. An example of valid taxonomies you could use in this scenario could be:

* GTDB: `d__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Enterobacterales;f__Vibrionaceae;g__Photobacterium;s__Photobacterium piscicola`
* NCBI: `1;131567;2759;33154;4751;451864;5204;452284;1538075;162474;742845;55193;76775`
:::

## Provided materials
You can follow [this link](https://docs.google.com/spreadsheets/d/1eT05boK8MkGq6MNOBMa1w0qHD-n5e5aU03_nu4CBBiA/edit?usp=sharing) to find a Google Spreasheet called `genome_uploader_template`. 

This spreadsheet contains a tab for every webin account assigned to this course's users. You should use the same accounts that have been assigned yesterday - you will find the list [here](https://docs.google.com/document/d/1VnV5sf4oETrHjXwRpT7RBB00wABGLES1/edit#heading=h.gjdgxs) or in Maira's documentation. Identify the tab assigned to your webin profile. You can use the table template in that tab to prepare a tsv as input file for the genome_uploader. Once you have filled in the table with all required values, export it as tsv (`File` --> `Download` --> `Tab-separated values (.tsv)`).

:::{.callout-warning}
Two tables need to be generated if you are submitting bins and MAGs - one for bins and one for MAGs.
:::

## Registering your genomes

:::{.callout-warning}
As you did yesterday, you will need to generate a study from your webin profile, and add it to the following command under `UPLOAD_STUDY`. You can either look it up on Maira's documentation from yesterday, or screenshotted at the end of this page.
:::

After generating the table, it will be time to launch the `genome_uploader`. You can do so by opening a terminal and typing:

```bash
python genome_upload.py -u UPLOAD_STUDY \
--genome_info METADATA_FILE (--mags | --bins) \
--webin WEBIN_ID --password PASSWORD \
--centre_name CENTRE_NAME [--out] [--force]
```

Where:

* `-u UPLOAD_STUDY`: study accession for genomes upload to ENA (in format ERPxxxxxx or PRJEBxxxxxx)
* `---genome_info METADATA_FILE` : genomes metadata file in tsv format
* `-m, --mags, --b, --bins`: select EITHER OF THESE for either bin or MAG upload
* `--out`: output folder (default: working directory)
* `--force`: sample xmls won't be regenerated automatically if a previous xml already exists. If any metadata or value in the tsv table changes, `--force` will allow xml regeneration.
* `--webin WEBIN_ID`: webin id (format: Webin_XXXXX)
* `--password PASSWORD`: webin password
* `--centre_name CENTRE_NAME`: name of the centre generating and uploading genomes

This step will also generate manifest files. 

## Submitting your genomes
After checking that all needed manifests exist, it is necessary to use ENA's webin-cli resource to upload genomes.

```bash
java -jar ~/JAR/webin-cli-8.0.0.jar \
-context=genome -manifest=MANIFEST_FILE \
-userName="Webin-XXX" -password="YYY" \
-test -submit
```
## Registering a study
![](genome_uploader/register_a_study.png)